{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words---------------------------------------------------------------\n",
    "Basically just elminating words that aren't important om the text, E.G\n",
    "\"the\", \"am\", \"were\" or similar words should be included at all\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'horse': 5, 'kingdom': 8, 'sense': 16, 'thing': 18, 'keeps': 7, 'betting': 1, 'people': 13, 'often': 11, 'said': 15, 'nothing': 10, 'better': 0, 'inside': 6, 'man': 9, 'outside': 12, 'spiritually': 17, 'well': 20, 'physically': 14, 'bigger': 2, 'foot': 3, 'heaven': 4, 'welcome': 19}\n",
      "(4, 21)\n",
      "  (0, 5)\t3\n",
      "  (0, 8)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 5)\t3\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 18)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 9)\t2\n",
      "  (2, 14)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 20)\t1\n",
      "  (3, 4)\t2\n",
      "  (3, 5)\t1\n",
      "  (3, 19)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "import pandas as pd\n",
    "corpus = [\"A horse, a horse, my kingdom for a horse!\",\n",
    "          \"Horse sense is the thing a horse has which keeps it from betting on people.\"\n",
    "          \"I’ve often said there is nothing better for the inside of the man, than the outside of the horse.\",\n",
    "          \"A man on a horse is spiritually, as well as physically, bigger then a man on foot.\",\n",
    "          \"No heaven can heaven be, if my horse isn’t there to welcome me.\"]\n",
    "\n",
    "#yes, we'll eliminating these dumb words\n",
    "vectorizer = text.CountVectorizer(stop_words=[\"my\", \"for\",\"the\", \"has\", \"than\", \"if\", \n",
    "                                            \"from\", \"on\", \"of\", \"it\", \"there\", \"ve\",\n",
    "                                            \"as\", \"no\", \"be\", \"which\", \"isn\", \"to\", \n",
    "                                            \"me\", \"is\", \"can\", \"then\"])\n",
    "vectorizer.fit(corpus)\n",
    "#check vocabularies\n",
    "print(vectorizer.vocabulary_)           #there's no word that've been put in the stop_words parameter\n",
    "token=vectorizer.transform(corpus)\n",
    "print(token.shape)\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>betting</th>\n",
       "      <th>bigger</th>\n",
       "      <th>foot</th>\n",
       "      <th>heaven</th>\n",
       "      <th>horse</th>\n",
       "      <th>inside</th>\n",
       "      <th>keeps</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>man</th>\n",
       "      <th>...</th>\n",
       "      <th>often</th>\n",
       "      <th>outside</th>\n",
       "      <th>people</th>\n",
       "      <th>physically</th>\n",
       "      <th>said</th>\n",
       "      <th>sense</th>\n",
       "      <th>spiritually</th>\n",
       "      <th>thing</th>\n",
       "      <th>welcome</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   better  betting  bigger  foot  heaven  horse  inside  keeps  kingdom  man  \\\n",
       "0       0        0       0     0       0      3       0      0        1    0   \n",
       "1       1        1       0     0       0      3       1      1        0    1   \n",
       "2       0        0       1     1       0      1       0      0        0    2   \n",
       "3       0        0       0     0       2      1       0      0        0    0   \n",
       "\n",
       "   ...  often  outside  people  physically  said  sense  spiritually  thing  \\\n",
       "0  ...      0        0       0           0     0      0            0      0   \n",
       "1  ...      1        1       1           0     1      1            0      1   \n",
       "2  ...      0        0       0           1     0      0            1      0   \n",
       "3  ...      0        0       0           0     0      0            0      0   \n",
       "\n",
       "   welcome  well  \n",
       "0        0     0  \n",
       "1        0     0  \n",
       "2        0     1  \n",
       "3        1     0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#token arr and using pandas to check each index\n",
    "import pandas as pd\n",
    "\n",
    "tokenarr=token.toarray()\n",
    "\n",
    "pd.DataFrame(tokenarr, columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 english stop words are:\n",
      "thereafter ,across ,un ,before ,onto ,seem ,will ,one ,latter ,his ,now ,whatever ,couldnt ,themselves ,twenty ,had ,if ,within ,find ,itself ,to ,beside ,"
     ]
    }
   ],
   "source": [
    "#arbitrary stop words\n",
    "stopwords=text.ENGLISH_STOP_WORDS\n",
    "n=20;i=0\n",
    "print(f'{n} english stop words are:')\n",
    "for word in stopwords:\n",
    "    print(f'{word}', end =\" ,\")\n",
    "    if i>n:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>with stop</th>\n",
       "      <td>0.657993</td>\n",
       "      <td>0.631565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without stop</th>\n",
       "      <td>0.649628</td>\n",
       "      <td>0.623532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  f1_accuracy\n",
       "with stop     0.657993     0.631565\n",
       "without stop  0.649628     0.623532"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparison using stop words and not using it\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#get data\n",
    "    #dummy\n",
    "dummytrain=fetch_20newsgroups(subset=\"train\",  remove=('headers', 'footers', 'quotes'))\n",
    "dummytest=fetch_20newsgroups(subset=\"test\",  remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "    #model with stop words and without\n",
    "withstop=text.CountVectorizer(stop_words=list(text.ENGLISH_STOP_WORDS))\n",
    "withoutstop=text.CountVectorizer()\n",
    "\n",
    "    #get labels\n",
    "trainlabel= dummytrain.target\n",
    "testlabel= dummytest.target \n",
    "\n",
    "    #get train/test data stop words model\n",
    "traindata= withstop.fit_transform(dummytrain.data)\n",
    "testdata= withstop.transform(dummytest.data)\n",
    "\n",
    "    #get train/test data without stop words model\n",
    "traindata1= withoutstop.fit_transform(dummytrain.data)\n",
    "testdata1= withoutstop.transform(dummytest.data)\n",
    "\n",
    "#model of multinomial classificatiom\n",
    "thefunny=MultinomialNB(alpha=0.05)\n",
    "\n",
    "#getting accuracy score\n",
    "    #with stop wods\n",
    "thefunny.fit(traindata, trainlabel)\n",
    "predicted=thefunny.predict(testdata)\n",
    "accuracy= accuracy_score(testlabel, predicted)\n",
    "f1accuracy= f1_score(testlabel, predicted, average=\"macro\")\n",
    "    #without stop words\n",
    "thefunny.fit(traindata1, trainlabel)\n",
    "predicted=thefunny.predict(testdata1)\n",
    "accuracy1= accuracy_score(testlabel, predicted)\n",
    "f1accuracy1= f1_score(testlabel, predicted, average=\"macro\")\n",
    "\n",
    "pd.DataFrame({\"accuracy\":[accuracy, accuracy1],\n",
    "              \"f1_accuracy\": [f1accuracy, f1accuracy1]}, index=[\"with stop\", \"without stop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 7, 'you': 9, 'cannot': 0, 'is': 3, 'horse': 2, 'my': 5, 'for': 1, 'on': 6, 'there': 8, 'man': 4}\n",
      "{'close', 'see', 'has', 'but', 'as', 'think', 'than', 'say', 'eyes', 'me', 'no', 'important', 'physically', 'foot', 'without', 'love', 'oxygen', 'isn', 'welcome', 'said', 'betting', 'which', 'be', 've', 'then', 'thing', 'keeps', 'from', 'often', 'better', 'outside', 'bigger', 'well', 'spiritually', 'the', 'nothing', 'inside', 'more', 'when', 'heaven', 'sometimes', 'your', 'can', 'kingdom', 'it', 'of', 'if', 'sense', 'live', 'to'}\n"
     ]
    }
   ],
   "source": [
    "#automatic stop words\n",
    "'''\n",
    "To automatically create a stop word list, we will start with the\n",
    "parameter min_df of CountVectorizer. When you set this threshold \n",
    "parameter, terms that have a document frequency strictly lower than the\n",
    "given threshold will be ignored. This value is also called cut-off in\n",
    "the literature. If a float value in the range of [0.0, 1.0] is used, \n",
    "the parameter represents a proportion of documents.\n",
    "'''\n",
    "Corpus = [\"\"\"People say you cannot live without love, \n",
    "             but I think oxygen is more important\"\"\",\n",
    "          \"Sometimes, when you close your eyes, you cannot see.\"\n",
    "          \"A horse, a horse, my kingdom for a horse!\",\n",
    "          \"\"\"Horse sense is the thing a horse has which \n",
    "          keeps it from betting on people.\"\"\"\n",
    "          \"\"\"I’ve often said there is nothing better for \n",
    "          the inside of the man, than the outside of the horse.\"\"\",\n",
    "          \"\"\"A man on a horse is spiritually, as well as physically, \n",
    "          bigger then a man on foot.\"\"\",\n",
    "          \"\"\"No heaven can heaven be, if my horse isn’t there \n",
    "          to welcome me.\"\"\"]\n",
    "\n",
    "vectorizer=text.CountVectorizer(min_df=2)       #automatic stop words\n",
    "vectorizer.fit(Corpus)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.stop_words_)       #list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   df   len(vocabulary)   len(stopwords)\n",
      "0.00                43                 0\n",
      "0.05                43                 0\n",
      "0.10                43                 0\n",
      "0.15                43                 0\n",
      "0.20                43                 0\n",
      "0.25                43                 0\n",
      "0.30                 7                36\n",
      "0.35                 7                36\n",
      "0.40                 7                36\n",
      "0.45                 7                36\n",
      "0.50                 7                36\n",
      "0.55                 1                42\n",
      "0.60                 1                42\n",
      "0.65                 1                42\n",
      "0.70                 1                42\n",
      "0.75                 1                42\n",
      "0.80                 1                42\n",
      "0.85                 1                42\n",
      "0.90                 1                42\n",
      "0.95                 1                42\n"
     ]
    }
   ],
   "source": [
    "#bruteforcing the optimal df used in automatic stop words\n",
    "import numpy as np\n",
    "print(f'   df   len(vocabulary)   len(stopwords)')\n",
    "for i in np.arange(0, 1, 0.05):\n",
    "    vectorizer=text.CountVectorizer(min_df=i)\n",
    "    vectorizer.fit(corpus)\n",
    "    print(f'{i:.2f}     {len(vectorizer.vocabulary_):13d}   {len(vectorizer.stop_words_):15d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   df   len(vocabulary)   len(stopwords)\n",
      "0.25                36                 7\n",
      "0.30                36                 7\n",
      "0.35                36                 7\n",
      "0.40                36                 7\n",
      "0.45                36                 7\n",
      "0.50                36                 7\n",
      "0.55                42                 1\n",
      "0.60                42                 1\n",
      "0.65                42                 1\n",
      "0.70                42                 1\n",
      "0.75                42                 1\n",
      "0.80                42                 1\n",
      "0.85                42                 1\n",
      "0.90                42                 1\n",
      "0.95                42                 1\n"
     ]
    }
   ],
   "source": [
    "#anoother parameter that can be used is max_df\n",
    "#bruteforcing the optimal df_max used in automatic stop words\n",
    "import numpy as np\n",
    "print(f'   df   len(vocabulary)   len(stopwords)')\n",
    "for i in np.arange(0.25, 1, 0.05):\n",
    "    vectorizer=text.CountVectorizer(max_df=i)\n",
    "    vectorizer.fit(corpus)\n",
    "    print(f'{i:.2f}     {len(vectorizer.vocabulary_):13d}   {len(vectorizer.stop_words_):15d}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
