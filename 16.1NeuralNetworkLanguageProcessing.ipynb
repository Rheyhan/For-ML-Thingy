{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccuracyScore: 0.8237919024814976\n",
      "f1Score      : 0.8219321249722576\n",
      "[[1285   28   14  155    4   40]\n",
      " [  62  858   23  100    4   62]\n",
      " [  45   24 1406   85    6   73]\n",
      " [  81   37   20 1643    6   68]\n",
      " [  27   37   22   51  422   31]\n",
      " [ 108   59   81  259    7 1955]]\n"
     ]
    }
   ],
   "source": [
    "#self explanotary, earlier we used the multinomialnb, now we gonna use the mlpclassifier in the neural network module\n",
    "\n",
    "#libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import random as rd\n",
    "\n",
    "def splitparagraphs(path, minsize=20):\n",
    "    with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "        splittedparas=[sentence for sentence in file.read().split(\"\\n\\n\") if len(sentence)>minsize]\n",
    "        return splittedparas\n",
    "\n",
    "\n",
    "#preparing data\n",
    "author = ['Virginia Woolf', 'Samuel Butler', 'Herman Melville', 'David Herbert Lawrence', 'Daniel Defoe', 'James Joyce']\n",
    "filenames=[\"night_and_day_virginia_woolf.txt\", \"the_way_of_all_flash_butler.txt\", \"moby_dick_melville.txt\", \"sons_and_lovers_lawrence.txt\", \"robinson_crusoe_defoe.txt\", \"james_joyce_ulysses.txt\"]\n",
    "folder=\"Files/\"\n",
    "data=[];counter=0;label=[]\n",
    "for file in filenames:\n",
    "    path=folder+file\n",
    "    paras=splitparagraphs(path, minsize=100)\n",
    "    label+=[counter]*len(paras)\n",
    "    data.extend(paras)\n",
    "    counter+=1\n",
    "\n",
    "#randomize\n",
    "merged=list(zip(data, label))\n",
    "merged=rd.sample(merged, len(merged))\n",
    "data, label = (list(zip(*merged)))\n",
    "\n",
    "#split train test\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.8, random_state=327364784)\n",
    "\n",
    "#turning the data into a vector\n",
    "vectorizer=text.CountVectorizer(stop_words=list(text.ENGLISH_STOP_WORDS))\n",
    "train_data=vectorizer.fit_transform(train_data)\n",
    "test_data=vectorizer.transform(test_data)\n",
    "\n",
    "#neural network here\n",
    "ANN=MLPClassifier(random_state=21763283, max_iter=300)\n",
    "ANN.fit(train_data, train_label)\n",
    "predicted=ANN.predict(test_data)\n",
    "print(f'AccuracyScore: {accuracy_score(test_label, predicted)}')\n",
    "print(f'f1Score      : {f1_score(test_label,predicted, average=\"macro\")}')\n",
    "print(confusion_matrix(test_label, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m stats \u001b[39mas\u001b[39;00m st\n\u001b[0;32m      3\u001b[0m \u001b[39m#trynna predict something cuz why not?\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m path\u001b[39m=\u001b[39mfolder\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmoby_dick_melville.txt\u001b[39m\u001b[39m\"\u001b[39m            \u001b[39m#try using that file cuz why not?\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dumdata\u001b[39m=\u001b[39msplitparagraphs(path, minsize\u001b[39m=\u001b[39m\u001b[39m75\u001b[39m)\n\u001b[0;32m      6\u001b[0m dumdata\u001b[39m=\u001b[39mrd\u001b[39m.\u001b[39msample(dumdata, \u001b[39m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folder' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats as st\n",
    "\n",
    "#trynna predict something cuz why not?\n",
    "path=folder+\"moby_dick_melville.txt\"            #try using that file cuz why not?\n",
    "dumdata=splitparagraphs(path, minsize=75)\n",
    "dumdata=rd.sample(dumdata, 5)\n",
    "\n",
    "dumdata=vectorizer.transform(dumdata)\n",
    "\n",
    "dumpredict=ANN.predict(dumdata)\n",
    "print(author[st.mode(dumpredict, keepdims= False)[0]])\n",
    "print(ANN.predict_proba(dumdata))\n",
    "\n",
    "#checking accuracy\n",
    "thecorrectlabelFR=[2]*dumdata.shape[0]\n",
    "accuracy_score(thecorrectlabelFR, dumpredict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
