{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTHOR PREDICTION\n",
    "\n",
    "Using:\n",
    "1. Virginia Woolf: Night and Day\n",
    "2. Samuel Butler: The Way of all Flesh\n",
    "3. Herman Melville: Moby Dick\n",
    "4. David Herbert Lawrence: Sons and Lovers\n",
    "5. Daniel Defoe: The Life and Adventures of Robinson Crusoe\n",
    "6. James Joyce: Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9042228994340444\n",
      "F1_score:   0.8952204728114234\n",
      "AccuracyScore: 0.8685241619503701\n",
      "f1Score      : 0.8714071301566909\n"
     ]
    }
   ],
   "source": [
    "#At this point, you can just predict someone's writing bruh :skull:\n",
    "\n",
    "#libraries needed\n",
    "import os\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random as rd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats as st\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def paragraphsplitter(path, minsize=20):\n",
    "    '''\n",
    "    Splitting your long ahh letter into several paragraphs.\n",
    "    As tring less than minsize will be ignored, default-20\n",
    "    '''\n",
    "    with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "        paragraphs=[sentence for sentence in file.read().split(\"\\n\\n\") if len(sentence)>minsize]\n",
    "    return paragraphs\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    #preparing data\n",
    "    data=[]     #empty list for the data later\n",
    "    label=[]    #empty list for the label\n",
    "    counter=0\n",
    "    author = ['Virginia Woolf', 'Samuel Butler', 'Herman Melville', 'David Herbert Lawrence', 'Daniel Defoe', 'James Joyce']\n",
    "    filenames=[\"night_and_day_virginia_woolf.txt\", \"the_way_of_all_flash_butler.txt\", \"moby_dick_melville.txt\", \"sons_and_lovers_lawrence.txt\", \"robinson_crusoe_defoe.txt\", \"james_joyce_ulysses.txt\"]\n",
    "    folder=\"Files/\"\n",
    "    \n",
    "        #we'll chop into paragraphs\n",
    "    for file in filenames:\n",
    "        path=folder+file\n",
    "        paragraphs=paragraphsplitter(path, 100)\n",
    "        data.extend(paragraphs)                             #merging to main data\n",
    "        label+=[counter]*len(paragraphs)                    #making the appropriate labe;\n",
    "        counter+=1\n",
    "\n",
    "    #randomize sample(cuz this is required for train_test_split)[Though we'll be using the entire population LOL]\n",
    "    merged = list(zip(data, label))\n",
    "    randomerge=rd.sample(merged, len(merged))\n",
    "    data,label = list(zip(*randomerge))\n",
    "    \n",
    "    #splitting data\n",
    "    train_data, test_data, train_label, test_label= train_test_split(data, label, train_size=0.8, random_state=217632)\n",
    "    \n",
    "    #We gotta vectorize the data first JESSE!\n",
    "    vectorizer=text.CountVectorizer(stop_words=list(text.ENGLISH_STOP_WORDS))\n",
    "    train_data=vectorizer.fit_transform(train_data)\n",
    "    test_data=vectorizer.transform(test_data)\n",
    "    \n",
    "    #Start classifying\n",
    "        #Get Model and fit\n",
    "    model=MultinomialNB(alpha=0.05)\n",
    "    model.fit(train_data, train_label)        \n",
    "    \n",
    "        #test score\n",
    "    predicted=model.predict(test_data)\n",
    "    print(f'Accuracy:   {accuracy_score(test_label, predicted)}')\n",
    "    print(f'F1_score:   {f1_score(test_label, predicted, average=\"macro\")}')\n",
    "    \n",
    "    ANN=MLPClassifier(random_state=21763283, max_iter=300)\n",
    "    ANN.fit(train_data, train_label)\n",
    "    predicted=ANN.predict(test_data)\n",
    "    print(f'AccuracyScore: {accuracy_score(test_label, predicted)}')\n",
    "    print(f'f1Score      : {f1_score(test_label,predicted, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author: Samuel Butler\n",
      "0.9766666666666667\n",
      "0.25\n",
      "[[  0   0   0   0]\n",
      " [  1 293   1   5]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#trying to use the classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "    #get a dummy data for predicting by using the way of all flash butler\n",
    "path=folder+\"the_way_of_all_flash_butler.txt\"               #we gonna use that folder, authot[1]\n",
    "dumparas=paragraphsplitter(path, minsize=200)\n",
    "\n",
    "    #randomizing\n",
    "dumparas=rd.sample(dumparas, 300)\n",
    "vecotrdumbparas=vectorizer.transform(dumparas)                  \n",
    "correctlabel=[1]*vecotrdumbparas.shape[0]                       #get the actual labels\n",
    "\n",
    "    #begin predicting\n",
    "predictdum=model.predict(vecotrdumbparas)\n",
    "\n",
    "    #printing result of prediction\n",
    "print(f'author: {author[st.mode(predictdum, keepdims=False)[0]]}')\n",
    "print(accuracy_score(correctlabel, predictdum))\n",
    "print(precision_score(correctlabel, predictdum, average=\"macro\"))\n",
    "print(confusion_matrix(correctlabel, predictdum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
